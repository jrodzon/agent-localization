
\chapter{Implementation} \label{chap:implementation}

\section{Working environment}

This section describes the working environment from both, software and hardware perspectives.

\subsection{Technology stack}

The following technology stack was used:
\begin{itemize}
  \item \textbf{Ubuntu 20.04} - Linux operating system widely used in the computer vision community. \cite{ubuntu-site}
  \item \textbf{Conda} - Package manager for isolated environments. \cite{conda-documentation}
  \item \textbf{Python 3.9.18} - Main programming language for writing code and conducting experiments. \cite{python}
  \item \textbf{CUDA 11.7.1} - A development environment for GPU-accelerated applications. \cite{cuda-toolkit}
  \item \textbf{PyTorch 1.13.1} - A machine learning framework with CUDA integration. \cite{pytorch}
\end{itemize}

\subsection{Workstation parameters}

The experiments were prepared and conducted on a personal computer with the following specifications:
\begin{itemize}
  \item CPU: Intel(R) Core(TM) i5-10400F CPU @ 2.90GHz \cite{intel-core-cpu}
  \item GPU: NVIDIA GeForce RTX 4060 \cite{nvidia-gpu}
  \item Hard Drive: Samsung SSD 990 PRO 2TB \cite{samsung-disc}
\end{itemize}

\section{Preparing test dataset}

To evaluate the algorithms' real-life usefulness,
I prepared a set of photos of various indoor scenes and outskirts of the building.
I shot each scene in two different lighting conditions - day and night.
A model for the scenes was the main building of the AGH faculty of Computer Science - D17.

\par

I took pictures using the rear camera of the \texttt{Samsung Galaxy A54 5G} phone, model \texttt{SM-A546B/DS}.
The image resolution is 4080x3060.
The horizontal field of view ($FoV_h$) is $\ang{72.7}$
and the vertical field of view ($FoV_v$) - $\ang{57.8}$. \cite{camera-fv-5-samsung-a54}

\subsection{Calculating Camera Matrix}

Many plane segmentation algorithms require camera intrinsic parameters
to correctly perform plane segmentation and depth prediction.
In this thesis, PlaneRCNN required the following camera matrix:
\begin{equation} \label{eq:camera-matrix}
	C = \begin{bmatrix}
		f_x &   0 & c_x & \\
		  0 & f_y & c_y & \\
		  0 &   0 &   1 & \\
	\end{bmatrix}
\end{equation}

where:
\begin{itemize}
\item $f_x$ is the focal length in pixels on x-axis
\item $f_y$ is the focal length in pixels on y-axis
\item $c_x$ is the principal point x-axis coordinate in pixels
\item $c_y$ is the principal point y-axis coordinate in pixels
\end{itemize}

Based on the pinhole camera model from Figure~\ref{figure:Pinhole-Camera-Model}
from Section~\ref{subsection:rgb-to-pc-mapping},
these are the mathematical recipes for all the necessary parameters:
\begin{equation} \label{eq:camera-intrinsic-parameters}
\begin{cases}
  f_x = \frac{\frac{1}{2}R_h}{\tan(\frac{1}{2}FoV_h)} \\
  f_y = \frac{\frac{1}{2}R_v}{\tan(\frac{1}{2}FoV_v)} \\
  c_x = \frac{1}{2}R_h \\
  c_y = \frac{1}{2}R_v
\end{cases}
\end{equation}

where:
\begin{itemize}
  \item $R_h$ is the camera horizontal resolution in pixels
  \item $R_v$ is the camera vertical resolution in pixels
  \item $FoV_h$ is the camera horizontal field of view in degrees
  \item $FoV_v$ is the camera vertical field of view in degrees
\end{itemize}

The image resolution is \texttt{4080x3060}, so $R_h = 4080$ and $R_v = 3060$. 
Fields of view are $FoV_h = \ang{72.7}$ and $FoV_v = \ang{57.8}$.
Applying these values to Equation 4.2 gives the following result:
\begin{equation} \label{eq:camera-intrinsic-parameters-solved}
\begin{cases}
  f_x = 2772.05 \approx 2772 \\
  f_y = 2771.59 \approx 2772 \\
  c_x = 2040 \\
  c_y = 1530
\end{cases}
\end{equation}

\section{Setting-up the environment}

The first step in using every repository is setting up the working environment.
Nowadays, almost every project using artificial intelligence is Python-oriented,
and algorithms incorporating some form of neural networks are no exception.
It is not coincidental.
The Python environment is rich in multiple sophisticated libraries,
providing means for many highly complicated tasks, such as matrix operations,
which are essential for any neural network manipulations.
Additionally, training a neural network requires immense computation,
and graphic cards (Graphic Processing Unit - GPU) are responsible for doing most of it.
GPUs have high computing capacity but are conventionally optimized for graphic problems.
Thus, separate dedicated drivers are necessary to transform a classic GPU
into a General Purpose Graphic Processing Unit (GPGPU) tuned for mathematical calculations.

\par

Ultimately, we end up with a tremendously complicated environment
with dedicated graphic drivers, python libraries, system libraries, etc.
Each of these components adds a layer of complexity.
Taking into consideration the environment specification,
getting a state-of-the-art neural network project going may be a highly challenging and time-consuming task.

\subsection{PlaneRCNN} \label{subsec:planercnn}

I started my work with an attempt to set up the PlaneRCNN repository. \cite{planercnn-repository}
The provided files seemed complete - an installation instruction followed by a \texttt{requirements.txt} file.
The installation went smoothly.
Next, I tried to run an example evaluation:
\begin{lstlisting}[language=bash,basicstyle=\small]
    $ python evaluate.py --methods=f --suffix=warping_refine --dataset=inference --customDataFolder=example_images
\end{lstlisting}
I received an error: GPU software cannot run \texttt{nms} - a part of the PlaneRCNN repository.
\begin{lstlisting}[language=bash,basicstyle=\small]
    Traceback (most recent call last):
    File "evaluate.py", line 20, in <module>
      from models.model import *
    File "/home/agent/Masters/Repos/planercnn/models/model.py", line 23, in <module>
      from nms.nms_wrapper import nms
    File "/home/agent/Masters/Repos/planercnn/nms/nms_wrapper.py", line 11, in <module>
      from nms.pth_nms import pth_nms
    File "/home/agent/Masters/Repos/planercnn/nms/pth_nms.py", line 2, in <module>
      from ._ext import nms
    File "/home/agent/Masters/Repos/planercnn/nms/_ext/nms/__init__.py", line 3, in <module>
      from ._nms import lib as _lib, ffi as _ffi
  ImportError: /home/agent/Masters/Repos/planercnn/nms/_ext/nms/_nms.so: undefined symbol: __cudaRegisterFatBinaryEnd
\end{lstlisting}

After a thorough investigation, I discovered that the PyTorch \cite{pytorch} in version \texttt{0.4.1}
supports only old  Compute Unified Device Architecture (CUDA) \cite{cuda-toolkit} versions,
which are incompatible with modern GPUs.

\par

Based on this knowledge, I tried to bump the PyTorch version to at least \texttt{1.10},
which supports some of the latest CUDA releases, but I encountered another obstacle.
There are two custom CUDA modules written in C \cite{c-language}:
\begin{itemize}
\item \texttt{nms} - implementation of Non-Maximum Suppression algorithm
\item \texttt{roi\_align} - implementation of RoIAlign algorithm proposed by He et al. \cite{inproceedingsMaskRCNN}
\end{itemize}

Unfortunately, PyTorch from version \texttt{1.0.0} has removed support for C modules
and left only the \texttt{C++} \cite{cpp-language} option.
(it was part of the \texttt{torch.legacy} package \cite{pytorch-release-1.0.0})
Thus, these custom modules needed to be rewritten.
After additional research, instead of changing them, I removed them completely,
thanks to the publicly available replacement by WeihongPan \cite{planercnn-repository-weihong-pan-fork}:

We can get rid of both custom modules:
\begin{itemize}
\item \texttt{nms}
Higher versions of the PyTorch library already provide the Non-Maximum Suppression algorithm,
so a version update is enough.
\item \texttt{roi\_align}
An implementation of the RoIAlign algorithm is now available as a separate package \cite{roialign-package},
so it is installed instead of using the custom module.
\end{itemize}
As a result, setting up the PlaneRCNN environment was simplified.

\par

WeihongPan also published a method of setting up the PlaneRCNN environment.
However, the installation failed with an error suggesting package incompatibilities.

It failed with the following error:
\begin{lstlisting}[language=bash]
Collecting cffi==1.15.0 (from -r requirements.txt (line 10))
  Using cached cffi-1.15.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.2 kB)
Collecting numpy==1.19.2 (from -r requirements.txt (line 11))
  Using cached numpy-1.19.2.zip (7.3 MB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... error
  error: subprocess-exited-with-error
  RuntimeError: Running cythonize failed!
\end{lstlisting}
which suggests package incompatibilities.

\par

On this ground, I decided to select my own set of compatible libraries
and ship them as a Conda \cite{conda-documentation} environment definition.
As a result, I created the \texttt{environment.yml} file:
\begin{lstlisting}[style=yaml]
name: planercnn_pytorch_1_13_cuda_11_7
channels:
  - pytorch
  - conda-forge
  - nvidia
  - defaults
dependencies:
  - cffi=1.15.1
  - matplotlib=3.8.4              # required by RoIAlign test.sh https://github.com/longcw/RoIAlign.pytorch
  - mkl=2024.0                    # due to a pytorch bug https://github.com/pytorch/pytorch/issues/123097
  - numpy=1.21.2
  - opencv=4.5.5
  - pytorch::pytorch=1.13.1
  - scikit-image=0.19.3
  - pytorch::torchvision=0.14.1   # required by RoIAlign test.sh https://github.com/longcw/RoIAlign.pytorch
  - tqdm=4.66.5
prefix: $HOME/.conda/envs/planercnn_pytorch_1_13_cuda_11_7
\end{lstlisting}

Additionally, I prepared a convenience script for RoIAlign installation:
\begin{lstlisting}[language=bash]
#!/bin/bash

WORKDIR="roi_align_installation"
GITHUB_URL="https://github.com/longcw/RoIAlign.pytorch"

mkdir $WORKDIR
git clone $GITHUB_URL $WORKDIR
cd $WORKDIR

python setup.py install
./test.sh

cd ..
rm -rf $WORKDIR
\end{lstlisting}

As a final step, I added an instruction which sets up the PlaneRCNN in just a few simple steps:
\begin{lstlisting}[language=bash]
$ conda env create -f environment.yml
$ conda activate planercnn_pytorch_1_13_cuda_11_7
$ conda install h5py=3.7.0
$ ./install_roi_align.sh
\end{lstlisting}

\subsection{PlaneRecNet}

With the PlaneRecNet repository \cite{planerecnet-repository},
there was a similar situation as with the PlaneRCNN (Section~\ref{subsec:planercnn}).
The whole Conda environment is exported to the file \texttt{environment.yml}, so, in theory,
anyone should be able to get it running with a simple command:
\begin{lstlisting}[language=bash]
$ conda env create -f environment.yml
\end{lstlisting}

Unfortunately, I encountered the following error stating that some libraries are incompatible:
\begin{lstlisting}[language=bash]
Solving environment: failed

LibMambaUnsatisfiableError: Encountered problems while solving:
  - package libopencv-4.5.3-py39h70bf20d_1 requires ffmpeg >=4.3.2,<4.4.0a0, but none of the providers can be installed

Could not solve for environment specs
The following packages are incompatible
  - ffmpeg ==4.4.0 h6987444_5 is requested and can be installed;
  - libopencv ==4.5.3 py39h70bf20d_1 is not installable because it requires
      - ffmpeg >=4.3.2,<4.4.0a0 , which conflicts with any installable versions previously reported.
\end{lstlisting}

To resolve the problem, I tried manipulating versions of the conflicting libraries.
But as a result, I always received even more errors.

To resolve the problem, I tried manipulating versions of the conflicting libraries but received even more errors.
Therefore, I decided to build a compatible set of libraries from scratch as a Conda environment definition.
I selected the same PyTorch and CUDA versions as in Section~\ref{subsec:planercnn}
and then fitted the rest of the dependencies.
As a result, the following \texttt{environment.yml} file was created:
\begin{lstlisting}[style=yaml]
name: PlaneRecNet
channels:
  - pytorch
  - conda-forge
  - nvidia
  - defaults
dependencies:
  - cffi=1.15.1
  - cuda-toolkit=11.7
  - numpy=1.21.2
  - opencv=4.5.3
  - pytorch::pytorch=1.13.1
  - scipy=1.7.1
  - pytorch::torchaudio=0.13.1
  - pytorch::torchvision=0.14.1
prefix: $HOME/.conda/envs/PlaneRecNet  
\end{lstlisting}

The final outcome is a one simple command setting the working environment for the PlaneRecNet:
\begin{lstlisting}[language=bash]
$ conda env create -f environment.yml
\end{lstlisting}

\section{Used Models Implementations}

For plane segmentation comparison I used trained models shared by the articles' authors
of both PlaneRCNN \cite{planercnn-repository} and PlaneRecNet \cite{planerecnet-repository}. 
